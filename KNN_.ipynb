{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alien-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "conventional-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "mob=pd.read_csv(r\"C:\\Users\\Nikita\\Downloads\\MarketPositioningofMobile\\Market Positioning of Mobile\\Dataset\\Mobile_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "synthetic-parking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>fc</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1.2</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  clock_speed  fc  int_memory  m_dep  mobile_wt  n_cores  \\\n",
       "0               842          2.2   1           7    0.6        188        2   \n",
       "1              1021          0.5   0          53    0.7        136        3   \n",
       "2               563          0.5   2          41    0.9        145        5   \n",
       "3               615          2.5   0          10    0.8        131        6   \n",
       "4              1821          1.2  13          44    0.6        141        2   \n",
       "...             ...          ...  ..         ...    ...        ...      ...   \n",
       "1995            794          0.5   0           2    0.8        106        6   \n",
       "1996           1965          2.6   0          39    0.2        187        4   \n",
       "1997           1911          0.9   1          36    0.7        108        8   \n",
       "1998           1512          0.9   4          46    0.1        145        5   \n",
       "1999            510          2.0   5          45    0.9        168        6   \n",
       "\n",
       "      pc  px_height  px_width   ram  sc_h  sc_w  talk_time  price_range  \n",
       "0      2         20       756  2549     9     7         19            1  \n",
       "1      6        905      1988  2631    17     3          7            2  \n",
       "2      6       1263      1716  2603    11     2          9            2  \n",
       "3      9       1216      1786  2769    16     8         11            2  \n",
       "4     14       1208      1212  1411     8     2         15            1  \n",
       "...   ..        ...       ...   ...   ...   ...        ...          ...  \n",
       "1995  14       1222      1890   668    13     4         19            0  \n",
       "1996   3        915      1965  2032    11    10         16            2  \n",
       "1997   3        868      1632  3057     9     1          5            3  \n",
       "1998   5        336       670   869    18    10         19            0  \n",
       "1999  16        483       754  3919    19     4          2            3  \n",
       "\n",
       "[2000 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interim-civilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   int64  \n",
      " 1   clock_speed    2000 non-null   float64\n",
      " 2   fc             2000 non-null   int64  \n",
      " 3   int_memory     2000 non-null   int64  \n",
      " 4   m_dep          2000 non-null   float64\n",
      " 5   mobile_wt      2000 non-null   int64  \n",
      " 6   n_cores        2000 non-null   int64  \n",
      " 7   pc             2000 non-null   int64  \n",
      " 8   px_height      2000 non-null   int64  \n",
      " 9   px_width       2000 non-null   int64  \n",
      " 10  ram            2000 non-null   int64  \n",
      " 11  sc_h           2000 non-null   int64  \n",
      " 12  sc_w           2000 non-null   int64  \n",
      " 13  talk_time      2000 non-null   int64  \n",
      " 14  price_range    2000 non-null   int64  \n",
      "dtypes: float64(2), int64(13)\n",
      "memory usage: 234.5 KB\n"
     ]
    }
   ],
   "source": [
    "mob.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fourth-blackjack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>2%</th>\n",
       "      <th>3%</th>\n",
       "      <th>4%</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>96%</th>\n",
       "      <th>97%</th>\n",
       "      <th>98%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>battery_power</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>1238.51850</td>\n",
       "      <td>439.418206</td>\n",
       "      <td>501.0</td>\n",
       "      <td>510.00</td>\n",
       "      <td>524.96</td>\n",
       "      <td>538.97</td>\n",
       "      <td>556.92</td>\n",
       "      <td>570.95</td>\n",
       "      <td>851.75</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>1615.25</td>\n",
       "      <td>1930.15</td>\n",
       "      <td>1946.08</td>\n",
       "      <td>1961.06</td>\n",
       "      <td>1974.00</td>\n",
       "      <td>1987.00</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clock_speed</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.52225</td>\n",
       "      <td>0.816004</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>4.30950</td>\n",
       "      <td>4.341444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_memory</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>32.04650</td>\n",
       "      <td>18.145715</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>48.00</td>\n",
       "      <td>61.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_dep</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.50175</td>\n",
       "      <td>0.288416</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile_wt</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>140.24900</td>\n",
       "      <td>35.399655</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>84.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>109.00</td>\n",
       "      <td>141.0</td>\n",
       "      <td>170.00</td>\n",
       "      <td>196.00</td>\n",
       "      <td>197.00</td>\n",
       "      <td>198.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_cores</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>4.52050</td>\n",
       "      <td>2.287837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>9.91650</td>\n",
       "      <td>6.064315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>px_height</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>645.10800</td>\n",
       "      <td>443.780811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>30.98</td>\n",
       "      <td>45.97</td>\n",
       "      <td>58.00</td>\n",
       "      <td>70.95</td>\n",
       "      <td>282.75</td>\n",
       "      <td>564.0</td>\n",
       "      <td>947.25</td>\n",
       "      <td>1485.05</td>\n",
       "      <td>1568.04</td>\n",
       "      <td>1618.03</td>\n",
       "      <td>1698.00</td>\n",
       "      <td>1791.01</td>\n",
       "      <td>1960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>px_width</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>1251.51550</td>\n",
       "      <td>432.199447</td>\n",
       "      <td>500.0</td>\n",
       "      <td>512.99</td>\n",
       "      <td>526.96</td>\n",
       "      <td>542.00</td>\n",
       "      <td>562.00</td>\n",
       "      <td>579.85</td>\n",
       "      <td>874.75</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>1633.00</td>\n",
       "      <td>1929.05</td>\n",
       "      <td>1947.00</td>\n",
       "      <td>1963.00</td>\n",
       "      <td>1974.00</td>\n",
       "      <td>1987.00</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>2124.21300</td>\n",
       "      <td>1084.732044</td>\n",
       "      <td>256.0</td>\n",
       "      <td>296.99</td>\n",
       "      <td>323.98</td>\n",
       "      <td>362.97</td>\n",
       "      <td>417.96</td>\n",
       "      <td>445.00</td>\n",
       "      <td>1207.50</td>\n",
       "      <td>2146.5</td>\n",
       "      <td>3064.50</td>\n",
       "      <td>3826.35</td>\n",
       "      <td>3864.04</td>\n",
       "      <td>3894.09</td>\n",
       "      <td>3922.06</td>\n",
       "      <td>3958.01</td>\n",
       "      <td>3998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_h</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>12.30650</td>\n",
       "      <td>4.213245</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_w</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>5.76700</td>\n",
       "      <td>4.356398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk_time</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>11.01100</td>\n",
       "      <td>5.463955</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_range</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>1.118314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count        mean          std    min      1%      2%      3%  \\\n",
       "battery_power  2000.0  1238.51850   439.418206  501.0  510.00  524.96  538.97   \n",
       "clock_speed    2000.0     1.52225     0.816004    0.5    0.50    0.50    0.50   \n",
       "fc             2000.0     4.30950     4.341444    0.0    0.00    0.00    0.00   \n",
       "int_memory     2000.0    32.04650    18.145715    2.0    2.00    2.00    3.00   \n",
       "m_dep          2000.0     0.50175     0.288416    0.1    0.10    0.10    0.10   \n",
       "mobile_wt      2000.0   140.24900    35.399655   80.0   80.00   82.00   83.00   \n",
       "n_cores        2000.0     4.52050     2.287837    1.0    1.00    1.00    1.00   \n",
       "pc             2000.0     9.91650     6.064315    0.0    0.00    0.00    0.00   \n",
       "px_height      2000.0   645.10800   443.780811    0.0   15.00   30.98   45.97   \n",
       "px_width       2000.0  1251.51550   432.199447  500.0  512.99  526.96  542.00   \n",
       "ram            2000.0  2124.21300  1084.732044  256.0  296.99  323.98  362.97   \n",
       "sc_h           2000.0    12.30650     4.213245    5.0    5.00    5.00    5.00   \n",
       "sc_w           2000.0     5.76700     4.356398    0.0    0.00    0.00    0.00   \n",
       "talk_time      2000.0    11.01100     5.463955    2.0    2.00    2.00    2.00   \n",
       "price_range    2000.0     1.50000     1.118314    0.0    0.00    0.00    0.00   \n",
       "\n",
       "                   4%      5%      25%     50%      75%      95%      96%  \\\n",
       "battery_power  556.92  570.95   851.75  1226.0  1615.25  1930.15  1946.08   \n",
       "clock_speed      0.50    0.50     0.70     1.5     2.20     2.80     2.90   \n",
       "fc               0.00    0.00     1.00     3.0     7.00    13.00    14.00   \n",
       "int_memory       4.00    5.00    16.00    32.0    48.00    61.00    62.00   \n",
       "m_dep            0.10    0.10     0.20     0.5     0.80     1.00     1.00   \n",
       "mobile_wt       84.00   86.00   109.00   141.0   170.00   196.00   197.00   \n",
       "n_cores          1.00    1.00     3.00     4.0     7.00     8.00     8.00   \n",
       "pc               0.00    0.00     5.00    10.0    15.00    20.00    20.00   \n",
       "px_height       58.00   70.95   282.75   564.0   947.25  1485.05  1568.04   \n",
       "px_width       562.00  579.85   874.75  1247.0  1633.00  1929.05  1947.00   \n",
       "ram            417.96  445.00  1207.50  2146.5  3064.50  3826.35  3864.04   \n",
       "sc_h             5.00    6.00     9.00    12.0    16.00    19.00    19.00   \n",
       "sc_w             0.00    0.00     2.00     5.0     9.00    14.00    15.00   \n",
       "talk_time        2.00    3.00     6.00    11.0    16.00    20.00    20.00   \n",
       "price_range      0.00    0.00     0.75     1.5     2.25     3.00     3.00   \n",
       "\n",
       "                   97%      98%      99%     max  \n",
       "battery_power  1961.06  1974.00  1987.00  1998.0  \n",
       "clock_speed       2.90     2.90     3.00     3.0  \n",
       "fc               15.00    16.00    16.00    19.0  \n",
       "int_memory       63.00    63.00    64.00    64.0  \n",
       "m_dep             1.00     1.00     1.00     1.0  \n",
       "mobile_wt       198.00   199.00   199.00   200.0  \n",
       "n_cores           8.00     8.00     8.00     8.0  \n",
       "pc               20.00    20.00    20.00    20.0  \n",
       "px_height      1618.03  1698.00  1791.01  1960.0  \n",
       "px_width       1963.00  1974.00  1987.00  1998.0  \n",
       "ram            3894.09  3922.06  3958.01  3998.0  \n",
       "sc_h             19.00    19.00    19.00    19.0  \n",
       "sc_w             15.00    16.00    17.00    18.0  \n",
       "talk_time        20.00    20.00    20.00    20.0  \n",
       "price_range       3.00     3.00     3.00     3.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mob.describe(percentiles=[0.01,.02,.03,.04,.05,.25,.5,.75,.95,.96,.97,.98,.99]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "growing-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=mob[\"price_range\"]\n",
    "x=mob.drop([\"price_range\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "official-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, y_test=train_test_split(x,y,test_size=.3, random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "related-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "virgin-concept",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on KNeighborsClassifier in module sklearn.neighbors._classification object:\n",
      "\n",
      "class KNeighborsClassifier(sklearn.neighbors._base.KNeighborsMixin, sklearn.base.ClassifierMixin, sklearn.neighbors._base.NeighborsBase)\n",
      " |  KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
      " |  \n",
      " |  Classifier implementing the k-nearest neighbors vote.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_neighbors : int, default=5\n",
      " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      " |  \n",
      " |  weights : {'uniform', 'distance'} or callable, default='uniform'\n",
      " |      Weight function used in prediction.  Possible values:\n",
      " |  \n",
      " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
      " |        are weighted equally.\n",
      " |      - 'distance' : weight points by the inverse of their distance.\n",
      " |        in this case, closer neighbors of a query point will have a\n",
      " |        greater influence than neighbors which are further away.\n",
      " |      - [callable] : a user-defined function which accepts an\n",
      " |        array of distances, and returns an array of the same shape\n",
      " |        containing the weights.\n",
      " |  \n",
      " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
      " |      Algorithm used to compute the nearest neighbors:\n",
      " |  \n",
      " |      - 'ball_tree' will use :class:`BallTree`\n",
      " |      - 'kd_tree' will use :class:`KDTree`\n",
      " |      - 'brute' will use a brute-force search.\n",
      " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
      " |        based on the values passed to :meth:`fit` method.\n",
      " |  \n",
      " |      Note: fitting on sparse input will override the setting of\n",
      " |      this parameter, using brute force.\n",
      " |  \n",
      " |  leaf_size : int, default=30\n",
      " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
      " |      speed of the construction and query, as well as the memory\n",
      " |      required to store the tree.  The optimal value depends on the\n",
      " |      nature of the problem.\n",
      " |  \n",
      " |  p : int, default=2\n",
      " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
      " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
      " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
      " |  \n",
      " |  metric : str or callable, default='minkowski'\n",
      " |      The distance metric to use for the tree.  The default metric is\n",
      " |      minkowski, and with p=2 is equivalent to the standard Euclidean\n",
      " |      metric. For a list of available metrics, see the documentation of\n",
      " |      :class:`~sklearn.metrics.DistanceMetric`.\n",
      " |      If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
      " |      must be square during fit. X may be a :term:`sparse graph`,\n",
      " |      in which case only \"nonzero\" elements may be considered neighbors.\n",
      " |  \n",
      " |  metric_params : dict, default=None\n",
      " |      Additional keyword arguments for the metric function.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of parallel jobs to run for neighbors search.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |      Doesn't affect :meth:`fit` method.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array of shape (n_classes,)\n",
      " |      Class labels known to the classifier\n",
      " |  \n",
      " |  effective_metric_ : str or callble\n",
      " |      The distance metric used. It will be same as the `metric` parameter\n",
      " |      or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
      " |      'minkowski' and `p` parameter set to 2.\n",
      " |  \n",
      " |  effective_metric_params_ : dict\n",
      " |      Additional keyword arguments for the metric function. For most metrics\n",
      " |      will be same with `metric_params` parameter, but may also contain the\n",
      " |      `p` parameter value if the `effective_metric_` attribute is set to\n",
      " |      'minkowski'.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_samples_fit_ : int\n",
      " |      Number of samples in the fitted data.\n",
      " |  \n",
      " |  outputs_2d_ : bool\n",
      " |      False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
      " |      otherwise True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
      " |  KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
      " |  RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
      " |  NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      " |  \n",
      " |  .. warning::\n",
      " |  \n",
      " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      " |     neighbors, neighbor `k+1` and `k`, have identical distances\n",
      " |     but different labels, the results will depend on the ordering of the\n",
      " |     training data.\n",
      " |  \n",
      " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> X = [[0], [1], [2], [3]]\n",
      " |  >>> y = [0, 0, 1, 1]\n",
      " |  >>> from sklearn.neighbors import KNeighborsClassifier\n",
      " |  >>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
      " |  >>> neigh.fit(X, y)\n",
      " |  KNeighborsClassifier(...)\n",
      " |  >>> print(neigh.predict([[1.1]]))\n",
      " |  [0]\n",
      " |  >>> print(neigh.predict_proba([[0.9]]))\n",
      " |  [[0.666... 0.333...]]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KNeighborsClassifier\n",
      " |      sklearn.neighbors._base.KNeighborsMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.neighbors._base.NeighborsBase\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the k-nearest neighbors classifier from the training dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples) if metric='precomputed'\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix} of shape (n_samples,) or                 (n_samples, n_outputs)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : KNeighborsClassifier\n",
      " |          The fitted k-nearest neighbors classifier.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the class labels for the provided data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_queries,) or (n_queries, n_outputs)\n",
      " |          Class labels for each data sample.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Return probability estimates for the test data X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_queries, n_classes), or a list of n_outputs                 of such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. Classes are ordered\n",
      " |          by lexicographic order.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
      " |  \n",
      " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
      " |      Find the K-neighbors of a point.\n",
      " |      \n",
      " |      Returns indices of and distances to the neighbors of each point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int, default=None\n",
      " |          Number of neighbors required for each sample. The default is the\n",
      " |          value passed to the constructor.\n",
      " |      \n",
      " |      return_distance : bool, default=True\n",
      " |          Whether or not to return the distances.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      neigh_dist : ndarray of shape (n_queries, n_neighbors)\n",
      " |          Array representing the lengths to points, only present if\n",
      " |          return_distance=True.\n",
      " |      \n",
      " |      neigh_ind : ndarray of shape (n_queries, n_neighbors)\n",
      " |          Indices of the nearest points in the population matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      In the following example, we construct a NearestNeighbors\n",
      " |      class from an array representing our data set and ask who's\n",
      " |      the closest point to [1,1,1]\n",
      " |      \n",
      " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
      " |      >>> neigh.fit(samples)\n",
      " |      NearestNeighbors(n_neighbors=1)\n",
      " |      >>> print(neigh.kneighbors([[1., 1., 1.]]))\n",
      " |      (array([[0.5]]), array([[2]]))\n",
      " |      \n",
      " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
      " |      element is at distance 0.5 and is the third element of samples\n",
      " |      (indexes start at 0). You can also query for multiple points:\n",
      " |      \n",
      " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
      " |      >>> neigh.kneighbors(X, return_distance=False)\n",
      " |      array([[1],\n",
      " |             [2]]...)\n",
      " |  \n",
      " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
      " |      Compute the (weighted) graph of k-Neighbors for points in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |          For ``metric='precomputed'`` the shape should be\n",
      " |          (n_queries, n_indexed). Otherwise the shape should be\n",
      " |          (n_queries, n_features).\n",
      " |      \n",
      " |      n_neighbors : int, default=None\n",
      " |          Number of neighbors for each sample. The default is the value\n",
      " |          passed to the constructor.\n",
      " |      \n",
      " |      mode : {'connectivity', 'distance'}, default='connectivity'\n",
      " |          Type of returned matrix: 'connectivity' will return the\n",
      " |          connectivity matrix with ones and zeros, in 'distance' the\n",
      " |          edges are distances between points, type of distance\n",
      " |          depends on the selected metric parameter in\n",
      " |          NearestNeighbors class.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : sparse-matrix of shape (n_queries, n_samples_fit)\n",
      " |          `n_samples_fit` is the number of samples in the fitted data.\n",
      " |          `A[i, j]` gives the weight of the edge connecting `i` to `j`.\n",
      " |          The matrix is of CSR format.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      NearestNeighbors.radius_neighbors_graph : Compute the (weighted) graph\n",
      " |          of Neighbors for points in X.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> X = [[0], [3], [1]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
      " |      >>> neigh.fit(X)\n",
      " |      NearestNeighbors(n_neighbors=2)\n",
      " |      >>> A = neigh.kneighbors_graph(X)\n",
      " |      >>> A.toarray()\n",
      " |      array([[1., 0., 1.],\n",
      " |             [0., 1., 1.],\n",
      " |             [1., 0., 1.]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "southwest-terry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.9521428571428572\n",
      "Test Score 0.9183333333333333\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_x, train_y)\n",
    "print(\"Train Score\",knn.score(train_x, train_y))\n",
    "print(\"Test Score\",knn.score(test_x, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "southeast-warrior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.95\n",
      "Test Score 0.9416666666666667\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(train_x, train_y)\n",
    "print(\"Train Score\",knn.score(train_x, train_y))\n",
    "print(\"Test Score\",knn.score(test_x, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "becoming-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myKNN(kn, verbose=True):  # verbos is used when u want to print in the function when print is reqired till the result is true \n",
    "    k=[]\n",
    "    train_acc=[]\n",
    "    test_acc=[]\n",
    "    for i in range(1,kn,2):\n",
    "        knni=KNeighborsClassifier(n_neighbors=i)\n",
    "        knni.fit(train_x, train_y)\n",
    "        k.append(i)\n",
    "        ktt=knni.score(train_x, train_y)\n",
    "        ktst=knni.score(test_x, y_test)\n",
    "        diff=ktt-ktst\n",
    "        train_acc.append( ktt)\n",
    "        test_acc.append( ktst)\n",
    "        if verbose:\n",
    "            print(f\"for k= {i} : train score { round(ktt,3)} and test score {round( ktst,3)}\")\n",
    "\n",
    "    plt.plot(k, train_acc, label=\"Train Accuracy\", color=\"red\")\n",
    "    plt.plot(k, test_acc, label=\"Test Accuracy\", color=\"blue\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.ylabel(\"Scores\")\n",
    "    plt.show()\n",
    "          \n",
    "    return k, train_acc, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confidential-fellowship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAz+klEQVR4nO3deXhUdZbw8e8hbIIiOyJBiIgCAgkQUQEFZEtoN0Bt1HZtdXBaXOged1tHxxletdsG27FHW0VtBRUapRVB2UQF2QSRVVACRCCEnYhsyXn/OBUSQvZU5SaV83meepK6dW/dc1OVOvXbRVVxzjnnClIt6ACcc85VbJ4onHPOFcoThXPOuUJ5onDOOVcoTxTOOecKVT3oAMKpcePG2rp166DDcM65SmPJkiU7VLVJYftEVaJo3bo1ixcvDjoM55yrNERkY1H7eNWTc865QnmicM45VyhPFM455woVVW0UzrnydeTIEVJTUzl48GDQobgi1K5dm9jYWGrUqFHiYz1ROOdKLTU1lVNOOYXWrVsjIkGH4wqgquzcuZPU1FTi4uJKfHzEqp5E5DUR2S4iKwp4XERkrIisF5HlItI112NJIrI29NiDkYrROVc2Bw8epFGjRp4kKjgRoVGjRqUu+UWyjWIckFTI48lA29DtDuAlABGJAV4MPd4BuFZEOkQwTudcGXiSqBzK8jpFLFGo6lxgVyG7XAG8qeZroL6INAe6A+tV9UdVPQxMCO0bGQcPwrPPwowZETuFc85VZkH2emoBbM51PzW0raDt+RKRO0RksYgsTk9PL3kUNWvCc8/B66+X/FjnXGB27txJQkICCQkJnHbaabRo0eLY/cOHDxd67OLFi7n77rtLfM6lS5ciIkyfPr20YVdKQTZm51cO0kK250tVXwZeBkhMTCz5KkzVqsGgQTB1KmRmQkxMiZ/COVf+GjVqxLJlywB44oknOPnkk/nDH/5w7PGjR49SvXr+H3GJiYkkJiaW+Jzjx4+nV69ejB8/nkGDBpUq7uLIzMwkpgJ9FgVZokgFWua6HwtsKWR75CQnw86dsGRJRE/jnIusm2++mVGjRtG3b18eeOABFi5cSI8ePejSpQs9evRg7dq1AMyZM4dLL70UsCRz66230qdPH84880zGjh2b73OrKhMnTmTcuHF8+umnxzUMP/PMM3Tq1In4+HgefND636xfv57+/fsTHx9P165d+eGHH447L8Bdd93FuHHjAJuC6Mknn6RXr168//77vPLKK5x33nnEx8czbNgwDhw4AEBaWhpDhgwhPj6e+Ph45s2bx2OPPcaYMWOOPe8jjzxS4HWURpAliinAXSIyATgf2KuqW0UkHWgrInHAT8Bw4LqIRjJgAIjAJ59A9+4RPZVzUeveeyH0DT9sEhLgL38p0SHff/89M2bMICYmhn379jF37lyqV6/OjBkzePjhh5k0adIJx6xZs4bZs2ezf/9+zjnnHO68884Txht89dVXxMXF0aZNG/r06cPUqVMZOnQon3zyCR988AELFiygTp067NplTbPXX389Dz74IEOGDOHgwYNkZWWxefPmE86dW+3atfnyyy8Bq1q7/fbbAXj00Ud59dVXGTlyJHfffTe9e/dm8uTJZGZmkpGRwemnn87QoUO55557yMrKYsKECSxcuLBEf7fCRCxRiMh4oA/QWERSgceBGgCq+jdgKjAYWA8cAG4JPXZURO4CpgMxwGuqujJScQLQuLEliGnT4PHHI3oq51xkXX311ceqbfbu3ctNN93EunXrEBGOHDmS7zG/+tWvqFWrFrVq1aJp06akpaURGxt73D7jx49n+PDhAAwfPpy33nqLoUOHMmPGDG655Rbq1KkDQMOGDdm/fz8//fQTQ4YMASwBFMevf/3rY7+vWLGCRx99lD179pCRkXGsqmvWrFm8+eabAMTExHDqqady6qmn0qhRI5YuXUpaWhpdunShUaNGxf2TFSliiUJVry3icQV+V8BjU7FEUn6SkuDJJ60KKox/YOeqjBJ+84+UunXrHvv9scceo2/fvkyePJmUlBT69OmT7zG1atU69ntMTAxHjx497vHMzEwmTZrElClTePrpp48NYNu/fz+qekLXU/t4O1H16tXJyso6dj/vuIbcsd9888188MEHxMfHM27cOObMmVPodd92222MGzeObdu2ceuttxa6b0n5XE/ZkpNBFT77LOhInHNhsnfvXlq0sE6T2W0BpTFjxgzi4+PZvHkzKSkpbNy4kWHDhvHBBx8wcOBAXnvttWNtCLt27aJevXrExsbywQcfAHDo0CEOHDhAq1atWLVqFYcOHWLv3r3MnDmzwHPu37+f5s2bc+TIEd5+++1j2/v168dLL70EWALbt28fAEOGDGHatGksWrQo7A3tniiyJSZaSeKTT4KOxDkXJvfffz8PPfQQPXv2JDMzs9TPM378+GPVSNmGDRvGO++8Q1JSEpdffjmJiYkkJCTw3HPPAfDWW28xduxYOnfuTI8ePdi2bRstW7bkmmuuoXPnzlx//fV06dKlwHM+9dRTnH/++QwYMIB27dod2z5mzBhmz55Np06d6NatGytXWs18zZo16du3L9dcc03Ye0xJQUWkyigxMVHLtHDRddfBzJmwdat1m3XOFWr16tW0b98+6DAckJWVRdeuXXn//fdp27Ztvvvk93qJyBJVLbSvsH8a5pacDNu3h7/nhnPORdCqVas466yz6NevX4FJoix89tjcBg60n598Al27Fr6vc85VEB06dODHH3+M2PN7iSK3Zs2gWzdvp3DOuVw8UeSVnAzz58Pu3UFH4pxzFYInirySkiAry2eTdc65EE8UeZ1/PtSvb6O0nXPOeWP2CapXt0btadNsAJ4vyuJchbRz50769esHwLZt24iJiaFJkyYALFy4kJo1axZ6/Jw5c6hZsyY9evQocJ8rrriC7du3M3/+/PAFXgl5iSI/SUmwZQssXx50JM65AmRPM75s2TJGjBjBfffdd+x+UUkCLFHMmzevwMf37NnDN998w549e9iwYUM4Qz9O3ulCKiJPFPlJCq3g6tVPzlUqS5YsoXfv3nTr1o1BgwaxdetWAMaOHUuHDh3o3Lkzw4cPJyUlhb/97W88//zzJCQk8MUXX5zwXJMmTeKyyy5j+PDhTJgw4dj2/KYPh/ynGu/Tpw/Zg4B37NhB69atAZtO5Oqrr+ayyy5j4MCBZGRk0K9fP7p27UqnTp348MMPj53vzTffpHPnzsTHx3PDDTewf/9+4uLijk1wuG/fPlq3bl3ghIfh4FVP+WneHOLjrZvsAw8EHY1zlULQs4yrKiNHjuTDDz+kSZMmvPvuuzzyyCO89tprjB49mg0bNlCrVi327NlD/fr1GTFixAmLHeU2fvx4Hn/8cZo1a8ZVV13FQw89BOQ/fXhBU40XZv78+SxfvpyGDRty9OhRJk+eTL169dixYwcXXHABl19+OatWreLpp5/mq6++onHjxuzatYtTTjmFPn368PHHH3PllVcyYcIEhg0bdsK06OHkiaIgycm2ROq+fVCvXtDROOeKcOjQIVasWMGAAQMAmzCvefPmAMfmVrryyiu58sori3yutLQ01q9fT69evRARqlevzooVK2jVqlW+04fnN9V4UQYMGHBsP1Xl4YcfZu7cuVSrVo2ffvqJtLQ0Zs2axVVXXUXjxo2Pe97bbruNZ555hiuvvJLXX3+dV155pQR/qZLzRFGQ5GQYPdrmfsozGZhz7kRBzzKuqpx77rn5Njx//PHHzJ07lylTpvDUU08dm0ivIO+++y67d+8mLi4OsOqdCRMmcP/99xd47rxTjcPx04oXNqX422+/TXp6OkuWLKFGjRq0bt2agwcPFvi8PXv2JCUlhc8//5zMzEw6duxY6PWUlbdRFOTCC60k4aO0nasUatWqRXp6+rFEceTIEVauXHlsZbm+ffvyzDPPHFsI6JRTTmH//v35Ptf48eOZNm0aKSkppKSksGTJEiZMmFDg9OH5TTUOtrzpktASyxMnTiww9r1799K0aVNq1KjB7Nmz2bhxI2BTir/33nvs3LnzuOcFuPHGG7n22mu55ZZbyvBXKx5PFAWpUQP698/pJuucq9CqVavGxIkTeeCBB4iPjychIYF58+aRmZnJb37zGzp16kSXLl247777qF+/PpdddhmTJ08+oTE7JSWFTZs2ccEFFxzbFhcXR7169ViwYEG+04cXNNX4H/7wB1566SV69OjBjh07Coz9+uuvZ/HixSQmJvL2228fm1b83HPP5ZFHHqF3797Ex8czatSo447ZvXs3115b6BpxYeHTjBfmlVfgjjtgxQo499zwPa9zUcKnGQ/OxIkT+fDDD3nrrbeKfUxppxn3NorCJCfbz08+8UThnKswRo4cySeffMLUqeWzYrRXPRUmNhY6dvTxFM65CuWFF15g/fr1nH322eVyPk8URUlKgi++gIyMoCNxrkKKpurraFaW18kTRVGSk+HwYZg9O+hInKtwateuzc6dOz1ZVHCqys6dO4+N+ygpb6MoSs+eULeutVNcdlnQ0ThXocTGxpKamkp6enrQobgi1K5dm9jY2FId64miKLVqQb9+lih8NlnnjlOjRo1jg9Jc9PKqp+JIToaUFPj++6Ajcc65cueJojiyZ5P1UdrOuSrIE0VxtG4N7dp5N1nnXJXkiaK4kpNhzhwIzeXinHNVhSeK4kpKgkOHLFk451wVEtFEISJJIrJWRNaLyIP5PN5ARCaLyHIRWSgiHXM9dp+IrBSRFSIyXkRK1wE4XC6+GE46yaufnHNVTsQShYjEAC8CyUAH4FoR6ZBnt4eBZaraGbgRGBM6tgVwN5Coqh2BGGB4pGItltq1oW9fb9B2zlU5kSxRdAfWq+qPqnoYmABckWefDsBMAFVdA7QWkWahx6oDJ4lIdaAOsCWCsRZPcjKsX28355yrIiKZKFoAm3PdTw1ty+1bYCiAiHQHWgGxqvoT8BywCdgK7FXVT/M7iYjcISKLRWRxxEeHZs8m69VPzrkqJJKJIr8hzHknhBkNNBCRZcBIYClwVEQaYKWPOOB0oK6I/Ca/k6jqy6qaqKqJTZo0CVvw+WrTBs46y6ufnHNVSiQTRSrQMtf9WPJUH6nqPlW9RVUTsDaKJsAGoD+wQVXTVfUI8E+gRwRjLb7kZJsgMM/6t845F60imSgWAW1FJE5EamKN0VNy7yAi9UOPAdwGzFXVfViV0wUiUkdsZfF+wOoIxlp8SUnwyy8wd27QkTjnXLmIWKJQ1aPAXcB07EP+PVVdKSIjRGREaLf2wEoRWYP1jrondOwCYCLwDfBdKM6XIxVrifTpYxMFevWTc66K8DWzSyMpCTZuhNUVo5DjnHOlVZw1s31kdmkkJcGaNTajrHPORTlPFKWR3U3Wq5+cc1WAJ4rSOPtsm1HWx1M456oATxSlIWKlipkzbaJA55yLYp4oSis5GX7+Gb76KuhInHMuojxRlFbfvlCzprdTOOeinieK0jr5ZLjoIk8Uzrmo54miLJKTYeVK2Ly56H2dc66S8kRRFklJ9tN7PznnopgnirLo0AFatvRE4ZyLap4oykLEShUzZsCRI0FH45xzEeGJoqySk2HfPpg3L+hInHMuIjxRlFW/flC9ulc/OeeilieKsqpXD3r29G6yzrmo5YkiHJKT4dtvYcuWovd1zrlKxhNFOGR3k50+Pdg4nHMuAjxRhEPnznD66V795JyLSp4owiG7m+xnn8HRo0FH45xzYeWJIlySkmDPHliwIOhInHMurDxRhMuAARAT49VPzrmo44kiXOrXhwsu8PEUzrmo44kinJKTYckSSEsLOhLnnAsbTxThlJxsPz/9NNg4nHMujDxRhFNCAjRt6u0Uzrmo4okinKpVs95P06dDZmbQ0TjnXFh4ogi35GTYtQsWLw46EuecCwtPFOE2YICVLLz6yTkXJTxRhFujRtC9uycK51zUiGiiEJEkEVkrIutF5MF8Hm8gIpNFZLmILBSRjrkeqy8iE0VkjYisFpELIxlrWCUlwaJFsGNH0JE451yZRSxRiEgM8CKQDHQArhWRDnl2exhYpqqdgRuBMbkeGwNMU9V2QDywOlKxhl1yMqh6N1nnXFSIZImiO7BeVX9U1cPABOCKPPt0AGYCqOoaoLWINBOResDFwKuhxw6r6p4IxhpeiYnQuLGP0nbORYVIJooWwOZc91ND23L7FhgKICLdgVZALHAmkA68LiJLReTvIlI3grGGV7VqMHCgJYqsrKCjcc65MolkopB8tmme+6OBBiKyDBgJLAWOAtWBrsBLqtoF+Bk4oY0DQETuEJHFIrI4PT09XLGXXXIypKfDCy94snDOVWqRTBSpQMtc92OB49YKVdV9qnqLqiZgbRRNgA2hY1NVNXvO7olY4jiBqr6sqomqmtikSZMwX0IZDBkCffrAvffCRRfBd98FHZFzzpVKJBPFIqCtiMSJSE1gODAl9w6hnk01Q3dvA+aGksc2YLOInBN6rB+wKoKxhl/dujBrFowbB2vXQpcucP/98PPPQUfmnHMlErFEoapHgbuA6ViPpfdUdaWIjBCREaHd2gMrRWQN1jvqnlxPMRJ4W0SWAwnAf0cq1ogRgZtuskRx883w7LPQoQP8619BR+acc8UmqnmbDSqvxMREXVyRp8748ksYMQJWroQrr4SxY6FlyyIPc865SBGRJaqaWNg+PjK7PPXqBd98A6NH28SB7dvDn//s62w75yo0TxTlrWZNeOABWLXKGrt//3sbd/H110FH5pxz+fJEEZTWra2tYtIkm+qjRw+4807YvTvoyJxz7jieKIIkAkOHwurV1o325ZehXTt45x2bAsQ55yqAYiUKEWkjIrVCv/cRkbtFpH5EI6tKTjnF2ioWL4ZWreD662268u+/Dzoy55wrdoliEpApImdh8y/FAe9ELKqqqksXmD8f/vd/LWl06gT/+Z9w8GDQkZXeL7946ci5Sq64iSIrNC5iCPAXVb0PaB65sKqwmBhrq1izBoYNgyeegM6dYcaMoCMrnh074J//hLvvhvh4G3h4/vnwxRdBR+acK6XiJoojInItcBPwUWhbjciE5AA47TRrq5g+3eaKGjDAqqTS0oKO7Hjbt8P778Ndd0HHjtCkiSW4v//dfv/DH2DLFrj4YmuPWbcu6IidcyVUrAF3oXUkRgDzVXW8iMQBv1bV0ZEOsCQq/IC70vrlF/if/7HxF3XqwMMPWzVV69ZwxhlQq1b5xbJ1K3z+ec5tdWiZkLp1oWdP6N3buv0mJlpXYIADB+D55y3+gwfh3/8d/vhHWw3QOReo4gy4K/bIbBE5CThDVdeGI7hIiNpEkW3NGvuQnT37+O3Nm1vSaN3aGsNz/96qFZx0UunPmZp6fGLIbmA/+WSb7LB3b7t16wY1iihkpqXB44/DK69YA/6jj8LIkeWb6JxzxwlbohCRy4DngJqqGiciCcCTqnp5WCINk6hPFGANw5s2QUoKbNxoP3P/vmnTiSO9mzU7MYHk/r1urqU+Nm2yhDBnjv384QfbXq+eJYY+fSwxdOkC1auX7hpWrYL/+A+YOtViGD0arrnGugs758pVOBPFEuASYE5ofQhE5DtV7RSWSMOkSiSKomRmWvVQ3gSSfdu0CQ4fPv6Yxo0tYezaBRs22Lb69a1dIbsqKT7eGtrDacYMG5m+fLk1eP/pT1Z95ZwrN8VJFMX9SnhUVffK8d/4vM9jRRQTA7GxduvV68THs7Jg27b8k8gZZ8A991hy6NQp/Ikhr/79be6rN9+0aqhevawh/P/9P2jTJrLnzuvIEeuSfPCgJUYv3Th3THFLFK9ia1s/CAwD7gZqqOqIQg8sZ16iqMR+/tlKFM88YyWe3/0OHnsMGjaMzPkOH4ZFi3Kq2ObNy1krZMAAG8ty1lmRObdzFUg4Z48dCZwLHMIG2u0F7i1TdM7lVreu9YRat87W7hg71koVf/4zHDpU9uc/dAjmzoWnnoJ+/axqrVcvK8ls2wa33AITJ9p5Fyywrr5PPhmecztXyRVZohCRGGC6qvYvn5BKz0sUUeS772xFwGnT4MwzrcH7qquKXyX0yy82I292b6358+1DX8QGMGY3yl90kbXR5LZ1K4waBRMmwNlnw0svwSWXhP0SnasIwtmYPQW4QVX3hiu4SPBEEYU+/dQG7X33HVx4oVVPXXjhifsdOGDJILsqacECq16qVg0SEnIa5S+6CBo0KN65p0+37sg//gi/+Y2du2nTMF6cc8ELZ6J4D7gA+Aw4tuizqt5d1iDDyRNFlMrMtLXHs6uJrrnG2i+2bMkpMSxcaA3S1arZmI7s8R29elk1U2n98gv8939bA3vduvbzttvsPM5FgXAmipvy266qb5QytojwRBHlMjLgueds7fEDB2xbTIyNAs+uSurZ08Z8hNuaNTYH15w5VqL529+sCsu5Si7cI7NrAmeH7q5V1SNljC/sPFFUEVu22PxS7dvbgk8nn1w+51WFt96ysR+7d8N999lI8/I6v3MREM4SRR/gDSAFEKAlcJOqzi1zlGHkicKVi1274MEHbSqSli3hr3+FyyvUJAUlp2rXtXEjpKdD27YQF+fjSaqAcA64+xMwMHueJxE5GxgPdCtbiM5VQg0b2mqEN90EI0bAFVfYbexYG7RYEalaAshv2pfsnxkZxx9Tr55VryUk2C0+Hs49t2xzh7lKqbiJokbuyQBV9XsR8WnGXdXWs6eNLP/LX2zdkA4dbKGpu+8ueoLEcFO1SRfzm7ol+/dffjn+mPr1ba6ts86ysSXZ8381bAhr18KyZfDtt9aRIDuJxMTAOefkJI7sn82alctlumAUt+rpNWzKjrdCm64HqqvqLRGMrcS86skFZuNGmwn3X/+yb+H/939wwQXhe/6srJw5vAoqFeQdHNioUf6TQGb/PPXU4p/7xx8taWQnj2XLYPPmnH1OO+34xJGQYGNQIj0NjCuzcLZR1AJ+B/TC2ijmAv+rqhVq2KonChcoVfjwQ0sYP/0Ed9xh64gUZ9xGZqYdk1+VUPZkjkfy9B9p0iQnAeSXECLdyL5rlyWN3Alk5cqcOGvXtjnDshPHBRdA167e7lHBhDNR1AUOqmpm6H4MUEtVD4Ql0jDxROEqhIwM6w01Zox9q//Tn+DXv7a1PfIrDaSk2GN5p4c/7bQTE0DudUbq1Cnf6yqOw4dtMau8pY9du+zxdu3gxhvhhhts4koXuHAmiq+B/qqaEbp/MvCpqvYIS6Rh4onCVSjLlsG//ZsNBhSxEkc2ETj99ILXCTnjDPtGHg1ULRFOnw5vvAFffmnX36+fdQgYOrRiJr0qIpyJYpmqJhS1LWieKFyFk5lpYy9++OH4ZNCyZdVd2e+HH2xq+TfftNLUySfD1Vdb0rjoIh/1Xs7CmSi+Akaq6jeh+4nAC6qaz6Q7wfFE4cri44/hs89sEttIzW7ucsnKgi++sFLG++9blV1cnFVL3Xhj+a9Jki0jw5b8bdvWluyNcuFMFOcBE4AtWO+n04Ffq+qSIo5LAsYAMcDfVXV0nscbAK8BbYCDwK2quiLX4zHAYuAnVb20qDg9UbjSGjPGBlqrWtX522/bAn+unPz8M0yebElj5kx7IXr1slLG1VcXv4dWSahaB4LstpTs9pT16+2xmjVt1uArrrABlaefHv4YKoAyJ4pQgtisqttC4yb+DRgKrAL+qKq7Cjk2BvgeGACkAouAa1V1Va59ngUyVPU/RaQd8KKq9sv1+CggEajnicJFQmamzSg+diwMGWLJ4re/tdqRRx6x0kVplwZ3pbR5M/zjH5Y01q61tpohQyxp9O9fui63hw/bfF25G9hzN7KDTWef3b33nHOsbenDD3PWje/ePWdwZYcOUdN7qziJAlUt8AZ8AzQM/X4xVqIYBjwFTCzi2AuxdSyy7z8EPJRnn4+BXrnu/wA0C/0ei62qdwnwUWHnyr5169ZNnSuujAzVyy9XBdVRo1SPHrXt+/er3nyzbb/wQtUNGwINs+rKylL9+mvVO+9UbdDAXpDTT1e9/37VlSsLPm7nTtVZs1Sff171pptUExJUa9Sw40G1dm3V885Tvf121b/+VfXLL1X37i04hhUrVJ9+2o7Jfo42bexN8/nnOW+cSgpYrEV8thZVovhWVeNDv78IpKvqE6H7hTZmi8hVQJKq3ha6fwNwvqrelWuf/wZqq+ooEekOzAvts0REJgL/A5wC/EELKFGIyB3AHQBnnHFGt40bNxZ4Pc5l27YNLrvMBlaPHWsrr+Y1YYJ1WgIbPzd8ePnG6HI5dAg++shKGVOnWlEwMdFKGc2bFz4QMO8o8rZtS19M3LIFpkyxksasWVZSadwYLr3UShoDB1a6HlzhKFGswEZgA6wBLs79WBHHXo21S2TfvwFrAM+9Tz3gdWAZNup7ERAPXIoN6APog5coXBitWKHaqpVqnTqq//pX4ftu2GClCrBSxv795RGhK1RampUWEhJyvuHHxKiee67qddepPvOM6vTpqtu2RTaOvXtV333XznnqqTmllcsvV331VYuzEqAYJYqiEsUjwFfAh8BScto0zgK+KuLYIque8uwv2Oy09bCSRGro/jbgAPCPoi7GE4UrysyZ9j992mmqixcX75gjR1Qfe0y1WjXVtm1VFy2KaIiuJFassBfkwIFg4zh8WHXGDNWRI1XPOMM+WkVUe/a0xPX998HGV4gyJwp7Di4AhgB1c207G+haxHHVgR+BOKAm8C1wbp596gM1Q7/fDryZz/N4icKFxbhxqtWr2xfPjRtLfvznn6vGxlp19zPPqGZmhj9GFwWyslSXLlV9/PHjSz3t26s+9JAltwokLImiLDdgMNbz6QfgkdC2EcAIzSl1rAtVa/0TaJDPc3iicGWSlaX6xz/au71/f9U9e0r/XDt3qg4dmvNcW7aEL04XpVJSVMeOVe3Xz6rIQLVbN9uWnh50dGVvzK5svHusy+vQIbj9dhscfeuttoJpWWcAV4W//x3uuceW0X79dWvLdK5I27fDO+9Yo/yyZfZm/NWvrFF+8GAbu1HOitOY7WPlXdTavRuSkixJ/Nd/2Yd7OJaJELHks2QJtGhhvafuvhsOHiz7c7so17Qp3HsvLF1qvbRGjoT5822cSIsW9kZasuT4ecEqAE8ULipt2GDLac+bZ6OsH3kk/OOj2reHr7+2//sXXrDxWKtWFXmYc6ZzZ5tZODXVuv727Wv9sBMTbXr2Z5+1NUgqAE8ULuosXGhLH6Sl2dxN110XuXPVrg3PP2/zRG3bBt26WfVWBftC6Cqy6tWt+um99+xN9NJLNsfU/ffbfDLJyTaoJ+8KheXIE4WLKpMnQ58+NiHp/PnlN1/T4MGwfLmd7847bebsnTvL59wuijRoYOuwz59vU448+KAtBnXttTaw8I474Kuvyv2biCcKFxVU7Zv9sGE2+Pbrr226nvJ02mnwySdWm/DxxxbHnDnlG4OLIuecA08/bVOxz5hhExO+/bZNlnj22fDUU7b4VTnwROEqvcxMawMcNcq+yc+aZauEBqFaNYvj66+tR9Qll1j7SN5VTJ0rtmrVbJGnN9+0qqnXX7cqqT/+0dY26dsXxo2L6JvMu8e6Si0jw0rlH30E//EfMHp0xVn3JiPDutC+9pqtUzR4sN0uuSTyy1m7KiAlxbr0vfGGLaP744+levOHbT2KysITRdWydauNX1i2DP76V2sbqIimTLEvgZ99Zssu1KwJvXvnJI62baNmxmoXBFWbrLBFi1Id7onCRa0VK6yjyM6d1llk8OCgIyraoUO2XPTUqdaWsXq1bW/TJidp9O4NJ50UbJyuavFE4YpF1cb9rFxpA9QGD4aOHSvet9x9+2zxs6lT4d13rQfhRx9Bly5BR1Y6GzZYwpg61dpVfvnFkkTfvjmJIy4u6ChdtPNE4Yrlscds5HKbNjmLecXG5nxY9esXTJ26qn3rnjrVbl9+ae119epZ1/Jnn7W6/2jwyy/w+eeWOD7+OOd1aNfOXoPkZLjoIqhVK9g4XfTxROGK9NprtvTnb38Lr7xiVZ3TptkH82efwf79Nu3FxRfnJI5zzolcaePnn2H27JzkkN37r1OnnPNfeGF4puKoyNaty/kbzJlj6+PUrWsrgWYnjmhJki5YnihcoWbMsA+cvn3tW2zeD9/Dh20KjOwPrJUrbXtcXM6Hdp8+ZV/QK/eH4uefW11+3bowYIDFV9U/FH/+2aqmsv9GmzbZ9qqWPMvDhg0578O2be1ve/750b1uuicKV6AVK6BnT2jVCr74Ak49tehjNm7MqVOfORMOHLApLLLr1JOTrfqqKAcP2j9i9gff+vW2PbuaZfBgG1Pk1Swnylsd98UX1jPy1FNtFc7Bg62d6bTTgo60cjh0yP6G2e/rNWtse2ys9arLzLTB0oMG2d920CCb1y+aeKJw+dq61b4lHT0KCxaU7tv6wYP2D5b9gfX997b97LNzPuwvvjjnwz4lJae3z8yZJzbcJifDmWeG7RKrjH37rGSY/UG3ZYtt79o153Xo3h1iYoKNsyLZvDnn7zVjhpXYatWy0nH2e7FtW9izxx7Pfo+npVmV63nn5fxtu3WrOON2SssThTtBRoZ1wVy7FubOtQ+UcFi/Puefb/bsnOqjiy+2JJHdFfTMM61bq3cFDT9Vm28q+4Nt3jzIyoKGDXN6sw0aBI0bBx1p+TpyxKZOyv67fPedbW/VKucDv29fe78WJCvLxutkP8fXX9vfu0mTnL/twIH2t65sPFG442RmwpVX2ht9yhT7wI6EAwcsWWSXHnKPSvbBZeVn92749NOcklx6uv3tzz8/5/Xo0qXyfyPOz7ZtOZ0yPv0U9u61dobcnTLatSv9e3HHjpy/7bRpNp6nWjVrK8p+/vj4yvFe90ThjskeK/Hii3b7938POiJXnrKybD2c7KSxcKG9J5o1s6qWwYOt80D9+kFHWjqZmXZN2d/4v/nGtp9++vHdvOvVi8y5Fy3KKVFnfwQ1b55z7v79I3PucPBE4Y55/nmbrO73v4fnngs6Ghe09HSYPj3nG/Hu3daO0aOHVU917GilvzPPtA4LFUlWlrXFrFtnbWNz59o17Npl3+p79Mj5gO7cufy/1ael5ZRmpk/PKc306mVTztx4Y3CTVubHE4UDbI2GYcNsZtX33ovOqgZXekePHv9tfOnSnMdE4IwzLGmcdZb9zL6deWbklnhWteqjdetOvK1ff/waPk2bHl8qatAgMjGVxtGjx7ePLF9uDefXXWcTRsbHBx2hJwqH9Wrq29fekLNmeeOxK9qePfZNff36Ez+kd+/O2a9aNWsQzp08sm+tWxc9rkMVtm8vOBn8/HPOvjVqWGLK71wtW1aeLz+rV9uyuW+8YW15vXtbwrj88uB6pnmiqOI2bLCGy5NPtl4a0db/25W/nTvz/2Bft8666maLibGBmblLIvXqnZh89u/POaZ69Zxjct/OOstKNdE06G33bnj1VZv1eONGS7h33WUzJJR3icgTRRW2e7fV1aalWTfJdu2CjshFM1Vr98hbKsj+PSPD9qtWzUob+ZUMWrWqeqPLjx61Hohjx9og1Dp14KabbCGu8vqf9URRRR06ZH27582z+ZrKa91o5/Kjal9Y9u+3ZBCpdo3KbtkySxjvvGP/w4MGWbXUoEGRrVorTqKoJDV7rrhU4bbbbCK511/3JOGCJ2JTirRt60miMAkJNknn5s22HPby5dZA3769VVHlrqYrb54ooswTT8A//mFvtOuuCzoa51xJNWkCjz5qMxq8/baNbRk50uafGjXKVjwtb54oosgbb8CTT8Itt8AjjwQdjXOuLGrWtC97CxZYZ5Rf/cp6TJ11ls2wMGuW1SCUB08UUWLmTKty6t8f/u//KsfUAc654jn/fGu7SEmBhx+Gr76ykebx8fD3vx8/riQSPFFEgVWrbEDdOefAxIlVr+eIc1VFixa2GuXmzdaeUa0a3H67lTIOHozceSOaKEQkSUTWish6EXkwn8cbiMhkEVkuIgtFpGNoe0sRmS0iq0VkpYjcE8k4K7Nt26zB66STbPGh4qwr4Zyr3GrXtirmpUut48qDD0Z2qpWIDWERkRjgRWAAkAosEpEpqroq124PA8tUdYiItAvt3w84CvxeVb8RkVOAJSLyWZ5jq7yff4bLLrP+63PnWtdD51zVIWKju3v3jux5Ilmi6A6sV9UfVfUwMAG4Is8+HYCZAKq6BmgtIs1UdauqfhPavh9YDbSIYKyVTmamNXR98w1MmGALqDjnXCREMlG0ADbnup/KiR/23wJDAUSkO9AKiM29g4i0BroAC/I7iYjcISKLRWRxenp6eCKvBEaNshGdY8ZYqcI55yIlkokiv343eTtzjQYaiMgyYCSwFKt2sicQORmYBNyrqvvIh6q+rKqJqprYpCLN3RtBY8bYCM777rP5YZxzLpIiOc1WKpB7NeZYYEvuHUIf/rcAiIgAG0I3RKQGliTeVtV/RjDOSmXSJEsQQ4bAs88GHY1zriqIZIliEdBWROJEpCYwHJiSewcRqR96DOA2YK6q7gsljVeB1ar65wjGWKl88AEMHw4XXGCjr4Oaltg5V7VErEShqkdF5C5gOhADvKaqK0VkROjxvwHtgTdFJBNYBfw2dHhP4Abgu1C1FMDDqjo1UvFWdFOmwNVXQ2KirZ5Vp07QETnnqgqfPbYS+OgjW52uSxdb0N3HSjjnwsVnj40CU6faqOv4eFt/15OEc668eaKowKZNs0brjh2tJFG/ftAROeeqIk8UFdSnn9oMkR062OJDFWnBeOdc1eKJogKaMQOuuMKWQpwxAxo2DDoi51xV5omigpk1y0Zat21rSaJRo6Ajcs5VdZ4oKpA5c+DSS23K4JkzoXHjoCNyzjlPFBXG55/bClZxcZYkqshsJM65SsATRQXwxReWJFq1sqqnpk2Djsg553J4ogjYV19BcjK0bGlJolmzoCNyzrnjeaII0Pz5kJRkyxvOmgWnnRZ0RM45dyJPFAH5+msYNMiSw6xZ0Lx50BE551z+PFEEYOFCSxJNm8Ls2VaicM65isoTRTlbvBgGDrSur7NnQ2xs0cc451yQPFGUo2++gQEDbKT17NnWgO2ccxWdJ4pysnQp9O9vs7/Ong1nnBF0RM45VzyeKMrBt99akjjlFEsSrVoFHZFzzhWfJ4oIW74c+vWDunUtScTFBR2Rc86VjCeKCFqxwpJE7dqWJM48M+iInHOu5DxRRMiqVXDJJVCzpiWJNm2Cjsg550rHE0UErF4NfftC9eqWJNq2DToi55wrPU8UYbZmjSWJatVsxPXZZwcdkXPOlY0nijD6/nurbgJLEu3aBRuPc86FQ/WgA4gW69ZZSeLoUVuAqH37oCNyzrnw8EQRBuvXW5I4fNjaJDp0CDoi55wLH08UZfTjj5YkDh60JNGxY9AROedceHmiKIMNGyxJHDhgbRKdOgUdkXPOhZ8nilJKSbEksX+/JYn4+KAjcs65yPBEUQqbNlmS2LsXZs6EhISgI3LOuciJaPdYEUkSkbUisl5EHszn8QYiMllElovIQhHpWNxjg7J5syWJ3bthxgzo2jXoiJxzLrIilihEJAZ4EUgGOgDXikje/kAPA8tUtTNwIzCmBMeWu9RUSxI7dsBnn0G3bkFH5JxzkRfJEkV3YL2q/qiqh4EJwBV59ukAzARQ1TVAaxFpVsxjy9VPP9lguu3b4dNP4bzzgozGOefKTyQTRQtgc677qaFtuX0LDAUQke5AKyC2mMeWm61bLUls3QrTp8P55wcViXPOlb9IJgrJZ5vmuT8aaCAiy4CRwFLgaDGPtZOI3CEii0VkcXp6ehnCzd+2bVbdtGULTJsGF14Y9lM451yFFsleT6lA7lWhY4EtuXdQ1X3ALQAiIsCG0K1OUcfmeo6XgZcBEhMT800mpZWWZiWJ1FRLEj17hvPZnXOucohkiWIR0FZE4kSkJjAcmJJ7BxGpH3oM4DZgbih5FHlspG3fbkli40aYOhV69SrPszvnXMURsRKFqh4VkbuA6UAM8JqqrhSREaHH/wa0B94UkUxgFfDbwo6NVKx5pafbynQbNliSuPji8jqzc85VPKIa1tqaQCUmJurixYvL9Bw7dliS+P57+PjjnGnDnXMuGonIElVNLGwfX48il507oX9/SxL/+pcnCeecA5/C45hdu2DAAFuhbsoUSxjOOee8RAHYdBwDBsCqVfDhhzBwYNAROedcxVHlSxT79lliWLECPvgABg0KOiLnnKtYqnyJ4qST4JxzYNIkSE4OOhrnnKt4qnyJokYN+Mc/go7COecqripfonDOOVc4TxTOOecK5YnCOedcoTxROOecK5QnCuecc4XyROGcc65Qniicc84VyhOFc865QkXVNOMikg5szLWpMbAjoHAiKVqvC6L32vy6Kp9ovba819VKVZsUdkBUJYq8RGRxUfOsV0bRel0Qvdfm11X5ROu1lea6vOrJOedcoTxROOecK1S0J4qXgw4gQqL1uiB6r82vq/KJ1msr8XVFdRuFc865sov2EoVzzrky8kThnHOuUFGZKEQkSUTWish6EXkw6HjCSURSROQ7EVkmIouDjqe0ROQ1EdkuIitybWsoIp+JyLrQzwZBxlhaBVzbEyLyU+h1WyYig4OMsTREpKWIzBaR1SKyUkTuCW2v1K9bIddVqV8zEaktIgtF5NvQdf1naHuJX6+oa6MQkRjge2AAkAosAq5V1VWBBhYmIpICJKpqpR4IJCIXAxnAm6raMbTtGWCXqo4OJfgGqvpAkHGWRgHX9gSQoarPBRlbWYhIc6C5qn4jIqcAS4ArgZupxK9bIdd1DZX4NRMRAeqqaoaI1AC+BO4BhlLC1ysaSxTdgfWq+qOqHgYmAFcEHJPLQ1XnArvybL4CeCP0+xvYP2ulU8C1VXqqulVVvwn9vh9YDbSgkr9uhVxXpaYmI3S3RuimlOL1isZE0QLYnOt+KlHwoueiwKciskRE7gg6mDBrpqpbwf55gaYBxxNud4nI8lDVVKWqnslLRFoDXYAFRNHrlue6oJK/ZiISIyLLgO3AZ6paqtcrGhOF5LMtmurXeqpqVyAZ+F2omsNVfC8BbYAEYCvwp0CjKQMRORmYBNyrqvuCjidc8rmuSv+aqWqmqiYAsUB3EelYmueJxkSRCrTMdT8W2BJQLGGnqltCP7cDk7GqtmiRFqovzq433h5wPGGjqmmhf9os4BUq6esWquueBLytqv8Mba70r1t+1xUtrxmAqu4B5gBJlOL1isZEsQhoKyJxIlITGA5MCTimsBCRuqHGNkSkLjAQWFH4UZXKFOCm0O83AR8GGEtYZf9jhgyhEr5uocbRV4HVqvrnXA9V6tetoOuq7K+ZiDQRkfqh308C+gNrKMXrFXW9ngBC3dj+AsQAr6nq08FGFB4iciZWigCoDrxTWa9NRMYDfbApj9OAx4EPgPeAM4BNwNWqWukahQu4tj5YFYYCKcC/ZdcTVxYi0gv4AvgOyAptfhirz6+0r1sh13Utlfg1E5HOWGN1DFYoeE9VnxSRRpTw9YrKROGccy58orHqyTnnXBh5onDOOVcoTxTOOecK5YnCOedcoTxROOecK5QnCuciSEQycv0+ODRj5xlBxuRcSVUPOgDnqgIR6Qe8AAxU1U1Bx+NcSXiicC7CROQibAqIwar6Q9DxOFdSPuDOuQgSkSPAfqCPqi4POh7nSsPbKJyLrCPAPOC3QQfiXGl5onAusrKwldLOE5GHgw7GudLwNgrnIkxVD4jIpcAXIpKmqq8GHZNzJeGJwrlyoKq7RCQJmCsiO1S1Uk3F7ao2b8x2zjlXKG+jcM45VyhPFM455wrlicI551yhPFE455wrlCcK55xzhfJE4ZxzrlCeKJxzzhXq/wNl6SQIph+DgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k, train_acc, test_acc=myKNN(30, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-organ",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
